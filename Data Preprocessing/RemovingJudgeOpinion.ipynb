{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUfWHd-lhJqy"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUkiRk7eOtpq"
   },
   "outputs": [],
   "source": [
    "districts = ['agra', 'aligarh', 'varanasi', 'lucknow', 'ghaziabad', 'ambedkar_nagar', 'bahraich', 'azamgarh',\n",
    "             'allahabad', 'balrampur', 'auraiya', 'barabanki', 'banda', 'bagpat', 'bhadohi', 'ballia', 'bijnor',\n",
    "             'basti', 'bareilly', 'bulandshahar', 'chitrakoot', 'deoria', 'budaun', 'etah', 'etawah', 'farrukhabad',\n",
    "             'faizabad', 'fatehpur', 'firozabad', 'gautam_buddha_nagar', 'ghazipur', 'hapur', 'gonda', 'hardoi',\n",
    "             'hamirpur_up', 'jaunpur', 'gorakhpur', 'jalaun', 'jyotiba_phule_nagar', 'jhansi', 'hathras', 'kanpur_dehat',\n",
    "             'kanpur_nagar', 'kannauj', 'kanshiramnagar', 'kheri', 'kaushambi', 'kushinagar', 'lalitpur', 'maharajganj',\n",
    "             'mainpuri', 'meerut', 'mahoba', 'mirzapur', 'mathura', 'moradabad', 'muzaffarnagar', 'pratapgarhdistrict', 'pilibhit',\n",
    "             'rampur', 'raebareli', 'mau', 'saharanpur', 'sant_kabir_nagar', 'shahjahanpur', 'shravasti', 'siddharthnagar', 'sitapur', 'unnao',\n",
    "             'sultanpur', 'sonbhadra']\n",
    "# districts = ['ghaziabad', 'agra', 'varanasi', 'aligarh', 'kanpurnagar', 'lucknow']\n",
    "assert len(districts) == 71\n",
    "def file(district):\n",
    "  return f\"../all_bail_cases_pickles/{district}/full_data_after_simple_NER_division.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVp4l2FzUYKn"
   },
   "source": [
    "# Paragraph Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gh9ZLM08qUu1"
   },
   "outputs": [],
   "source": [
    "split_text_1 = ['विद्वान अधिवक्ता', 'विद्वान अधिवक्त', 'उभय पक्ष के तर्कों', 'विद्धान अधिवक्ता', 'उभय पक्ष के तकों', 'उभय पक्षों', \n",
    "                'उभय पक्षो', 'केस डायरी', 'सुना', 'दर्ज बयान', 'सुना', \"उभय पक्ष के तर्को\", \"संलग्नप्रपत्रों\", \"उभय पक्ष\", \"प्रथम सूचना रिपोर्ट, केस डायरी\",\n",
    "                \"प्रथम सूचना रिपोर्ट, पुलिस प्रपत्र\"] \n",
    "split_text_2 = ['अवलोकन किया', 'परिशीलन किया', \"अवलोकन के उपरान्त\", \"परीशिलन किया\", \"परिशीलन कर लिया है\", \"के अवलोकन से स्पष्ट\"]\n",
    "\n",
    "terms_to_look_for = {\n",
    "    \"s_judge\": [\n",
    "          split_text_1, split_text_2  # same sentence\n",
    "    ],\n",
    "    \"judge_part_2\": [\n",
    "      [ \"उभय पक्ष की बहस सुनने\", \n",
    "       \"पत्रावली के अवलोकन\", \"प्रपत्रों के अवलोकन से\", \"केस डायरी के अवलोकन से विदित\", \n",
    "       \"प्रपत्रो के अवलोकन से विदित\", \"केस डायरी के अवलोकन से स्पष्ट\", \"प्रपत्रों का सम्यक परिशीलन किया\", \"पत्रावली का अवलोकन करने से स्पष्ट\",\n",
    "       \"जमानत के प्रकम पर साक्ष्य का विश्लेषण\", \"जमानत के प्रक्रम पर साक्ष्य का विश्लेषण\", \"न्यायालय द्वारा मामले के समस्त तथ्यों एवं परिस्थितियों\", \n",
    "       \"अभियोजन प्रपत्रों का अवलोकन किया गया\", \"इस स्तर पर गुण-दोष के आधार पर तथ्यों का मूल्यांकन करना\", \"केस डायरी व प्रथम सूचना रिपोर्ट के अवलोकन से स्पष्ट\",\n",
    "       \"अभियोजन प्रपत्रं के अवलोकन से\", \"अभियोजन प्रपत्रों के अवलावेकन से स्पष्ट होता है\", \"तर्कों को सुना\", \"केस डायरी व अभियोजन प्रपत्रों के सम्यक रूपेण परिशीलन\",\n",
    "       \"उपरोक्त तथ्य, परिस्थितियों तथा प्राथमिकी का अवलोकन करने से\", \"उपरोक्त समस्त तथ्य एवं परिस्थितियों को दृष्टिगत\", \"जमानतप्रार्थना पत्र पर सुना गया\", \n",
    "       \"पत्रावली के परिशीलन से स्पष्ट है\", \"विवेचना के दौरान दिनांक\", \"पत्रावली पर उपलब्ध पुलिस प्रपत्र व अन्य प्रलेखों के अवलोकनसे\", \"पत्रावली का अवलोकन किया\",\n",
    "       \"मामले के तथ्यों व परिस्थितियों में पूरी तरह से स्पष्ट है\", \"केस डायरी में उपलब्ध साक्ष्य के अनुसार\"\n",
    "      ]            \n",
    "    ],\n",
    "    \"facts by prosecutor\": [\n",
    "            [ \"अभियोजन कथन इस प्रकार है\", \"अभियोजन का कथन इस प्रकार है\", \"अभियोजन कथानक के अनुसार\", \"अभियोजन कथानक इस प्रकार है\",\n",
    "             \"अभियोजन कथानक यह है कि वादी\", \"अभियोजन के अनुसार पुलिस द्वारा दिनांक\", \"संक्षेप में अभियोजन केस के अनुसार\", \"संक्षेप में अभियोजन कथानक इस प्रकार है\", \n",
    "             \"अभियोजन के अनुसार प्रार्थी\", \"अभियोजन केस के अनुसार वादी\", \"अभियोजन केस के अनुसार\", \"संक्षेप में अभियोजन के अनुसार कथन\",\n",
    "             \"अभियोजन कथानक संक्षेप में इस प्रकार है\", \"अभियोजन के अनुसार दिनांक\", \"अभियोजन पक्ष के कथनानुसार\", \"अभियोजन के अनुसार अभियुक्त\", \n",
    "             \"अभियोजन के अनुसार वादी मुकदमा\"\n",
    "            ]\n",
    "    ],\n",
    "    \"public prosecutor\": [\n",
    "            [\"जमानत का विरोध करते हुये अभियोजन की ओर से तर्क दिया गया है\", \n",
    "             \"विरोध मे अभियोजन का तर्क\", \"जमानत प्रार्थनापत्र के विरूद्ध आपत्ति\", \n",
    "             \"जमानत का घोर विरोध\",  \"अभियोजन द्वारा जमानत प्रार्थना पत्र का विरोध किया गया है\", \"जमानत प्रार्थना पत्रका विरोध करते हुए कहा\",\n",
    "             \"विद्वान सहायक जिला शासकीय अधिवक्ता (फौजदारी) द्वारा जमानत प्रार्थना पत्र काविरोध किया गया है\", \n",
    "             \"अभियोजन की तरफ से सहायक जिला शासकीय अधिवक्ता, फौजदारी द्वारा जमानतप्रार्थना पत्र का इस आधार पर विरोध किया गया\", \n",
    "             \"विद्वान जिला शासकीय अधिवक्ता (फौजदारी)द्वारा प्रार्थनापत्र काविरोध करते हुए कथन किया है कि\", \n",
    "             \"जमानत प्रार्थना पत्र का विरोध\", \"प्रार्थनापत्र का विरोध\",\n",
    "             \"विद्वान अभियोजन अधिकारी द्वारा जमानत का विरोध\", \"जमानत प्रार्थना-पत्रका विरोध\", \"विद्वान जिला शासकीय अधिवक्ता (फौजदारी)द्वारा विरोध करते हुए तर्क\", \n",
    "             \"प्रार्थनापत्र का घोर विरोध\", \"जमानत प्रार्थनापत्र काकड़ा विरोध\", \"जमानतका विरोध करते हुए तर्क दिया गया\", \n",
    "             \"जमानत का विरोध करते हुए कथनकिया गया कि\", \"जमानत का विरोध\", \"जमानत प्रा० पत्र का विरोध\", \"जमानत प्रार्थना-पत्र काविरोध\"\n",
    "             ]\n",
    "    ],\n",
    "    \"defendant\": [\n",
    "            [\"अभियुक्त के विद्वान अधिवक्ता का तर्क है\", \"अभियुक्त की ओर से विद्वान अधिवक्ता द्वारा जमानत प्रार्थना पत्र पर बल देते हुए\", \n",
    "             \"अभियुक्त के विद्वान अधिवक्ता द्वारा जमानत प्रार्थना पत्र में यह आधार\", \"अभियुक्त निर्दोष है\", \n",
    "             \"अभियुक्त के विद्वान अधिवक्ता द्वारा तर्क प्रस्तुत किए गए कि\", \"अभियुक्त निर्दोष है\", \"बचाव पक्ष द्वारा यह आधार लिया गया\", \n",
    "             \"अभियुक्तगण की तरफ से जमानत प्रार्थना पत्र में कथन किया गया है\", \"विद्वान अधिवत्ता प्रार्थी /अभियुक्त ने तथ्य एवं विधि के तर्को\", \n",
    "             \"में झूठा एवं रंजिशन फंसाया गया\", \"में झूंठा व रंजिशन फंसाया गया\", \"विद्वान अधिवक्ता द्वारा निम्नलिखित तर्क किये गये\", \n",
    "             \"अभियुक्त की ओर से विद्वान अधिवक्ता द्वारा तर्क प्रस्तुत किया गया है\", \"अभियुक्तनिर्दोष है\", \n",
    "             \"अभियुक्त की तरफ से जमानत प्रार्थना पत्र में कथन किया गया है\", \"अभियुक्त निर्दोषहै\", \"अभियुक्त ने तर्क प्रस्तुत करते हुए कहा है कि\", \n",
    "             \"अभियुक्तगण की ओर से विद्वान अधिवक्तागण द्वारा जमानत प्रार्थना पत्र पर बल देते हुए तर्क प्रस्तुत किये गये\",\n",
    "             \"जमानत प्रार्थना पत्रो के समर्थन में\", \"अभियुक्त द्वारा जमानत पर अवमुक्त किये जाने के लिए\", \n",
    "             \"अभियुक्त की ओर से उसके विद्वान अधिवक्ता द्वारा जमानत प्रार्थनापत्र पर बहसकरते हुए\", \n",
    "             \"अभियुक्तगण की ओर से जमानत प्रार्थनापत्र में मुख्य आधार यह लिए गये हैं\", \"अभियुक्तपर लगाया गया आरोप पूर्णतया असत्य व निराधार है\", \n",
    "             \"अभियुक्त के विद्वान अधिवक्ता की ओर से तर्क दिया गया कि\", \"अभियुक्तागण की ओर से कथन किया गया है कि\", \n",
    "             \"अभियुक्त के विद्वान अधिवक्ता की तरफ से मुख्य तर्क यह दिये गये है\", \"अभियुक्तगण की ओर से विद्वान अधिवक्ता द्वारा जमानत प्रार्थना पत्र पर बल देते हुए\",\n",
    "             \"अभियुक्ता की ओर से यह आधार लिया गया है कि\", \"अभियुक्तानिर्दोष है\", \"अभियुक्तगण की ओर से यह तर्क दिया गया है\", \n",
    "             \"अभियुक्त के विद्वान अधिवक्ता द्वारा जमानत प्रार्थना-पत्र पर बहस करते हुए\", \"अभियुक्त को उक्त केस में झूठा फॅसाया गयाहै\", \\\n",
    "             \"बचाव पक्ष के अधिवक्ता द्वारा तर्क प्रस्तुत किया गया\", \"अभियुक्त द्वारा जमानत पर अवमुक्त किये जाने के लिए अपने अनुरोधके समर्थन में\", \n",
    "             \"अभियुक्तगण की ओर से बहस करते हुऐ उसके विद्वान अधिवक्ता द्वारा तर्क दियागया\"\n",
    "             ]\n",
    "    ],\n",
    "    # \"p_initial declaration\": [\n",
    "    #     [\"प्रस्तुत प्रतिभू आवेदन\", \"प्रार्थना पत्र के समर्थन में\", \"प्रथम जमानत प्रार्थना-पत्र\", \"प्रथम जमानत प्रार्थनापत्र\", \"जमानत प्रार्थना पत्र\", \"जमानत प्रार्थना-पत्र\"], \n",
    "    #     [\"किसी अन्य न्यायालय में\", \"अन्य किसी न्यायालय में\", \"किसी न्यायालय\", \"अन्यन्यायालय\", \"अन्य न्यायालय\"]         #same para\n",
    "    # ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpG_Ch9edJ_k"
   },
   "outputs": [],
   "source": [
    "names =[]\n",
    "import os\n",
    "files = os.listdir(\"./ner_data/ner_data/\")\n",
    "for file_ in files:\n",
    "  with open(f\"./ner_data/ner_data/{file_}\") as f:\n",
    "    import json\n",
    "    names+=json.load(f)\n",
    "import re\n",
    "names = set(names)\n",
    "names.remove(\"किया\")\n",
    "names.remove(\"प्रार्थना\")\n",
    "names.remove(\"गया\")\n",
    "names.remove(\"लिया\")\n",
    "def remove_NER(text):\n",
    "  text = re.sub(r'((\\+*)((0[ -]*)*|((91 )*))((\\d{12})+|(\\d{10})+))|\\d{5}([- ]*)\\d{6}', '<फ़ोन-नंबर>', text)\n",
    "  text = re.sub(r'((\\+*)((०[ -]*)*|((९१ )*))((\\d{१2})+|(\\d{१०})+))|\\d{५}([- ]*)\\d{६}', '<फ़ोन-नंबर>', text)\n",
    "  text = text.split()\n",
    "  punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "  for i,it in enumerate(text):\n",
    "    for p in punc:\n",
    "      it = it.replace(p,\"\")\n",
    "    #print(it)\n",
    "    if it in names:\n",
    "      text[i]=\"<नाम>\"\n",
    "  return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cths2LcOdMTP"
   },
   "outputs": [],
   "source": [
    "regex_arrays = [split_text_1, split_text_2, terms_to_look_for['judge_part_2'][0], terms_to_look_for[\"facts by prosecutor\"][0],\n",
    "                terms_to_look_for[\"public prosecutor\"][0], terms_to_look_for[\"defendant\"][0]]\n",
    "\n",
    "for i in regex_arrays:\n",
    "  for j in  range(len(i)):\n",
    "    i.append(remove_NER(i[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRHbiPH8eSl0",
    "outputId": "d5c72e3c-c3fa-4c81-a728-f012044d8a87"
   },
   "outputs": [],
   "source": [
    "terms_to_look_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoEtkYKNxt7A"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def strip_spaces(string):\n",
    "    no_spaces = ''\n",
    "\n",
    "    for pos, char in enumerate(string):\n",
    "        if re.match(r'\\S', char):  # upper \\S matches non-whitespace chars\n",
    "            no_spaces += char\n",
    "    return no_spaces\n",
    "\n",
    "def compile_regex(list_of_terms):\n",
    "  expression = re.compile(\n",
    "        '(' + \n",
    "        '|'.join(re.escape(strip_spaces(item)) for item in list_of_terms) +\n",
    "        ')')\n",
    "  \n",
    "  return expression\n",
    "\n",
    "def check_for_presence_of_any_one(content, expression):\n",
    "    if not expression.search(content):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "terms_to_look_for_regex = {\n",
    "}\n",
    "\n",
    "for i in terms_to_look_for:\n",
    "  r_list = []\n",
    "  for j in terms_to_look_for[i]:\n",
    "    r_list.append(compile_regex(j))\n",
    "  terms_to_look_for_regex[i] = r_list\n",
    "\n",
    "\n",
    "def find_labels(paras):\n",
    "  para_temp = []\n",
    "\n",
    "  ## For para level\n",
    "  # for i in paras:\n",
    "  #   para_temp.append(strip_spaces(i))\n",
    "  \n",
    "  # ## For sentence level\n",
    "  for i in paras:\n",
    "    para_temp.extend(list(map(strip_spaces, re.split(\"।|\\|\", i))))\n",
    "\n",
    "  paras = para_temp\n",
    "\n",
    "  para_labels = [None]*len(paras)\n",
    "\n",
    "  starter = 0\n",
    "\n",
    "  for i in paras[:]:\n",
    "    \n",
    "    for term in terms_to_look_for_regex:\n",
    "      if term.startswith(\"p_\"):\n",
    "        results = []\n",
    "        for j in terms_to_look_for_regex[term]:\n",
    "          results.append(check_for_presence_of_any_one(i, j))\n",
    "        if all(results):\n",
    "          if para_labels[starter] is None:\n",
    "            para_labels[starter] = {term}\n",
    "          else:\n",
    "            para_labels[starter].add(term)\n",
    "\n",
    "      elif term.startswith(\"s_\"):\n",
    "        sentencewise = re.split(\"।|\\|\", i)\n",
    "\n",
    "        for sentence in sentencewise:\n",
    "          results = []\n",
    "          for j in terms_to_look_for_regex[term]:\n",
    "            results.append(check_for_presence_of_any_one(i, j))\n",
    "          if all(results):\n",
    "            if para_labels[starter] is None:\n",
    "              para_labels[starter] = {term}\n",
    "            else:\n",
    "              para_labels[starter].add(term)\n",
    "      else:\n",
    "        for j in terms_to_look_for_regex[term]:\n",
    "          if check_for_presence_of_any_one(i, j):\n",
    "            if para_labels[starter] is None:\n",
    "              para_labels[starter] = {term}\n",
    "            else:\n",
    "              para_labels[starter].add(term)\n",
    "\n",
    "    starter += 1\n",
    "\n",
    "  return para_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9k8O4czKT1ua"
   },
   "outputs": [],
   "source": [
    "# annotating every sentence\n",
    "def get_sentences_of_para(para):\n",
    "  para_temp = []\n",
    "  para_temp.extend(re.split(\"।|\\|\", para))\n",
    "  \n",
    "  return para_temp\n",
    "\n",
    "def annotate_all(paras):\n",
    "  paras, labels_found = paras[0], paras[1]\n",
    "  sentence_counter = 0\n",
    "  current_label = None\n",
    "  # print(labels_found, len(labels_found))\n",
    "  for para in paras:\n",
    "     current_label = None\n",
    "     sentences = get_sentences_of_para(para)\n",
    "    #  print(sentences)\n",
    "\n",
    "     for i in sentences:\n",
    "      #  print(sentence_counter, i)\n",
    "       present = labels_found[sentence_counter]\n",
    "       if present is not None and 'facts by prosecutor' in present and 'public prosecutor' in present:\n",
    "         present = {'public prosecutor'}\n",
    "\n",
    "       if current_label is not None:\n",
    "         if present is None:\n",
    "           labels_found[sentence_counter] = current_label\n",
    "         else:\n",
    "           if present is not None and len(present) == 1:\n",
    "             current_label = present\n",
    "             labels_found[sentence_counter] = current_label\n",
    "       else:\n",
    "         if present is not None and len(present) == 1:\n",
    "             current_label = present\n",
    "             labels_found[sentence_counter] = current_label\n",
    "\n",
    "       sentence_counter += 1\n",
    "\n",
    "  # print(labels_found)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QMR2dytRuSI"
   },
   "outputs": [],
   "source": [
    "total_count = 0\n",
    "def analyse(r, labels_found, case):\n",
    "    global total_count\n",
    "    # r['labels'] = labels_found\n",
    "    not_after_wards = 0\n",
    "    total_idx = 0\n",
    "    judge_opinion = None\n",
    "    arguments = None\n",
    "    num_tokens = 0\n",
    "    total_idx += 1\n",
    "    labels = set()\n",
    "\n",
    "    s1 = False\n",
    "    s2 = False\n",
    "    done = False\n",
    "    ptr = len(labels_found) - 1\n",
    "    for s3 in labels_found[::-1]:\n",
    "      if done:\n",
    "        break\n",
    "      if s3 is not None:\n",
    "        for s in s3:\n",
    "          if s == 's_judge' or s == 'judge_part_2':\n",
    "            s1 = True\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "          if (s == 'public prosecutor' or s == 'defendant' or s == 'facts by prosecutor'):\n",
    "            s2 = True\n",
    "\n",
    "      elif not done:\n",
    "        # print(\"Assigning\")\n",
    "        labels_found[ptr] = {'s_judge'}\n",
    "        ptr -= 1\n",
    "\n",
    "    if s1 and not s2:\n",
    "      not_after_wards += 1\n",
    "      judge_opinion = []\n",
    "      arguments = []\n",
    "\n",
    "      cnt = 0\n",
    "\n",
    "      for i in r['body']:\n",
    "        sentences = get_sentences_of_para(i)\n",
    "        args = \"\"\n",
    "        opinions = \"\"\n",
    "        set_ = False\n",
    "        for j in sentences:\n",
    "          if j.isspace() or len(j) == 0:\n",
    "            cnt += 1\n",
    "            continue\n",
    "          if labels_found[cnt] is not None and (\"s_judge\" in labels_found[cnt] or \"judge_part_2\" in labels_found[cnt]):\n",
    "            opinions += j + \"। \"\n",
    "            set_ = True\n",
    "          elif labels_found[cnt] is None and set_:\n",
    "            opinions += j + \"। \"\n",
    "          else:\n",
    "            args += j + \"। \"\n",
    "            set_ = False\n",
    "          cnt += 1\n",
    "\n",
    "        if len(args) != 0:\n",
    "          arguments.append(args)\n",
    "        if len(opinions) != 0:\n",
    "          judge_opinion.append(opinions)\n",
    "\n",
    "      if judge_opinion is not None and len(judge_opinion) != 0 and len(arguments) != 0:\n",
    "        # print(case)\n",
    "        total_count += 1\n",
    "        r['segments'] ={\n",
    "          'judge-opinion': judge_opinion,\n",
    "          'facts-and-arguments': arguments\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQCWJivqRmPh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT3TNpG4RbAO"
   },
   "source": [
    "# Worker code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-GXrZB6PG4B"
   },
   "outputs": [],
   "source": [
    "def work(district):\n",
    "#   global total_count\n",
    "# district = 'agra'\n",
    "  print(f\"Enter: {district}\")\n",
    "  with open(file(district), 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "  for court in data.keys():\n",
    "    df = pd.DataFrame(data[court]['processed']).T\n",
    "    \n",
    "    final_df = df\n",
    "    if len(final_df) == 0:\n",
    "      continue\n",
    "    final_df['labels_found'] = final_df['body'].apply(find_labels)\n",
    "    final_df[['body', 'labels_found']].apply(annotate_all, axis = 1)\n",
    "\n",
    "    for case in data[court]['processed'].keys():\n",
    "      temp = data[court]['processed'][case]\n",
    "      analyse(temp, final_df.loc[case]['labels_found'], case)\n",
    "  # print(total_count)\n",
    "\n",
    "  with open(file(district), 'w') as f:\n",
    "    json.dump(data, f)  \n",
    "  print(f\"Exit: {district}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hqq8yo9XW4Zi",
    "outputId": "db9687d5-f4c2-4e56-f4a1-49b621a2b306"
   },
   "outputs": [],
   "source": [
    "work(\"bagpat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2nBClU9W7i7",
    "outputId": "d9208627-c044-482a-e22a-4a4f1abec7ce"
   },
   "outputs": [],
   "source": [
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00mrwdaj2cex",
    "outputId": "120b014a-636a-415a-f7c6-d3a1081b7bdd"
   },
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmRMJI-HZmMR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "indexes = []\n",
    "correct = []\n",
    "court = list(data.keys())[0]\n",
    "for idx in data[court]['processed']:\n",
    "  if 'segments' not in data[court]['processed'][idx]:\n",
    "    if len(data[court]['processed'][idx]['body']) >= 4:\n",
    "    #   distinct = set()\n",
    "      # for i in data[court]['processed'][idx]['labels']:\n",
    "    #     if i is None:\n",
    "    #       continue\n",
    "    #     for j in i:\n",
    "    #       distinct.add(j)\n",
    "    #   if len(distinct) > 1:\n",
    "        indexes.append(idx)\n",
    "  # else:\n",
    "  #   correct.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBbvpvNNqqke"
   },
   "outputs": [],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WO-AbPs5ZiXK",
    "outputId": "29d4f830-92c5-4e8c-cf77-dbbb3dd12eea"
   },
   "outputs": [],
   "source": [
    "data[court]['processed'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MC0ivMVIZmXC",
    "outputId": "f86f8a20-63da-40cc-bf42-1998f370ed9a"
   },
   "outputs": [],
   "source": [
    "data[court]['processed'][indexes[50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADyoQkOBamOU",
    "outputId": "1c688f65-2740-43b0-cdb1-621e3316c5c9"
   },
   "outputs": [],
   "source": [
    "len(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NwsmCIlWbKeM",
    "outputId": "ec572319-4def-4203-f569-919b1572f6c8"
   },
   "outputs": [],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Icdv4l694qyh"
   },
   "outputs": [],
   "source": [
    "print(data[court]['processed'][check]['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hS1xrNPzbNDv",
    "outputId": "35272050-59bb-46f0-8f55-602cd5d93862"
   },
   "outputs": [],
   "source": [
    "check = indexes[3028]\n",
    "print(data[court]['processed'][check]['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUYFbBn-bhMc",
    "outputId": "d8b089ef-c6f4-45df-89b2-f9915418c4e9"
   },
   "outputs": [],
   "source": [
    "data[court]['processed'][check]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Bwu1jPzeNsU",
    "outputId": "c360df26-61a6-4584-915b-e4983368c18d"
   },
   "outputs": [],
   "source": [
    "for i in data[court]['processed'][check]['body']:\n",
    "  j = get_sentences_of_para(i)\n",
    "  for k in j:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3M_OVJ_h8VA",
    "outputId": "16533c2c-3512-4fe3-ae4e-a3a19e702e07"
   },
   "outputs": [],
   "source": [
    "for i in data[court]['processed'][check]['body']:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BH7FoXdXdNBU",
    "outputId": "96a8e13a-e30f-4ad1-b81f-1196682974af"
   },
   "outputs": [],
   "source": [
    "data[court]['processed'][check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyG1DpE0zf6v"
   },
   "outputs": [],
   "source": [
    "def work_count(district):\n",
    "  print(f\"Enter: {district}\")\n",
    "  filename = file(district)\n",
    "  df = pd.read_json(filename, orient = 'index')\n",
    "  for i in df.index:\n",
    "      # print(i)\n",
    "      df1 = pd.DataFrame(df['processed'][i])\n",
    "      df1 = df1.T\n",
    "      if len(df1) == 0:\n",
    "        continue\n",
    "      # final_df = df1[df1['decision'] != \"don't know\"]\n",
    "      final_df = df1\n",
    "      total = len(final_df)\n",
    "      if 'segments' in final_df.columns:\n",
    "        final_df = final_df.dropna(subset=['segments'])\n",
    "        processed = len(final_df)\n",
    "        print(district, \",\", i, \",\", processed, \",\", total)\n",
    "      else:\n",
    "        print(district, \",\", i, \",\", 0, \",\", total)\n",
    "\n",
    "  print(f\"Exit: {district}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bfF1Ueh3zIv",
    "outputId": "5e87a958-4b15-49b9-cbd2-ea153f4302b1"
   },
   "outputs": [],
   "source": [
    "work_count('ghaziabad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R00awRHSQFos",
    "outputId": "19fb5a00-00c3-4407-b69f-3a9ad225e1df"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "district_chunks = []\n",
    "# SET CHUNK SIZE\n",
    "chunk_size = 71\n",
    "len1, len2 = len(districts), 0\n",
    "for i in range(0, len(districts), chunk_size):\n",
    "  district_chunks.append(districts[i:min(len(districts), i + chunk_size)])\n",
    "  len2 += len(district_chunks[-1])\n",
    "  print(district_chunks[-1])\n",
    "assert len2 == len1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIJo8CoSovK0",
    "outputId": "990421bb-c259-452a-b3a8-18805469cd35"
   },
   "outputs": [],
   "source": [
    "aba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpX7C5CBPi6Y",
    "outputId": "819cdc29-1ac5-4481-b6b0-541fd259d971",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import tqdm\n",
    "all_districts_stats = []\n",
    "for dst in tqdm.tqdm(districts):\n",
    "  val = work_count(dst)\n",
    "  all_districts_stats.append(val)\n",
    "\n",
    "# with Pool(20) as p:\n",
    "#   for _ in tqdm.tqdm(p.map(work, district_chunks[0]), total=len(district_chunks[0])):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.to_csv(\"districtwise_judge_opinion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zdzx_MSSqb-T",
    "outputId": "e27d8050-887b-48c1-9733-14fb719a5412"
   },
   "outputs": [],
   "source": [
    "total_count"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RemovingJudgeOpinion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
