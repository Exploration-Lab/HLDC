{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.pool import ThreadPool as Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = ['agra', 'aligarh', 'varanasi', 'lucknow', 'ghaziabad', 'ambedkar_nagar', 'bahraich', 'azamgarh',\n",
    "             'allahabad', 'balrampur', 'auraiya', 'barabanki', 'banda', 'bagpat', 'bhadohi', 'ballia', 'bijnor',\n",
    "             'basti', 'bareilly', 'bulandshahar', 'chitrakoot', 'deoria', 'budaun', 'etah', 'etawah', 'farrukhabad',\n",
    "             'faizabad', 'fatehpur', 'firozabad', 'gautam_buddha_nagar', 'ghazipur', 'hapur', 'gonda', 'hardoi',\n",
    "             'hamirpur_up', 'jaunpur', 'gorakhpur', 'jalaun', 'jyotiba_phule_nagar', 'jhansi', 'hathras', 'kanpur_dehat',\n",
    "             'kanpur_nagar', 'kannauj', 'kanshiramnagar', 'kheri', 'kaushambi', 'kushinagar', 'lalitpur', 'maharajganj',\n",
    "             'mainpuri', 'meerut', 'mahoba', 'mirzapur', 'mathura', 'moradabad', 'muzaffarnagar', 'pratapgarhdistrict', 'pilibhit',\n",
    "             'rampur', 'raebareli', 'mau', 'saharanpur', 'sant_kabir_nagar', 'shahjahanpur', 'shravasti', 'siddharthnagar', 'sitapur', 'unnao',\n",
    "             'sultanpur', 'sonbhadra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(districts) == 71\n",
    "HOME = \"../all_bail_cases_pickles/\"\n",
    "def file(district):\n",
    "  return f\"{HOME}/{district}/full_data_after_simple_NER_division.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_per_district = {}\n",
    "\n",
    "for district in tqdm(districts):\n",
    "  with open(file(district), 'r') as f:\n",
    "    data = json.load(f)\n",
    "#   print(district)\n",
    "  text = \"\"\n",
    "  for court in data.keys():\n",
    "    df = pd.DataFrame(data[court]['processed']).T\n",
    "    for idx, i in df.iterrows():\n",
    "      text += i['header'] + \" \".join(i['body']) + i['result']\n",
    "    for i in data[court]['valid']:\n",
    "        text += data[court]['valid'][i]\n",
    "  text_per_district[district] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_per_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(text_per_district, open(\"textperdistrict\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_per_district = pickle.load(open(\"textperdistrict\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_per_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_count = 0\n",
    "for dst in text_per_district:\n",
    "    sent_count += text_per_district[dst].count(\"ред\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e97e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_text = {}\n",
    "\n",
    "for i in tqdm(text_per_district):\n",
    "    txt = text_per_district[i]\n",
    "    txt = txt.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    txt = txt.translate(str.maketrans(string.digits, ' '*len(string.digits)))\n",
    "    updated_text[i] = txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(updated_text.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[0][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'[^(\\s|ред||)]+', corpus[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d2ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(token_pattern=r'[^(\\s|ред||)]+', stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in districts:\n",
    "    txt = updated_text[i]\n",
    "    response = vectorizer.transform([txt])\n",
    "    feature_array = np.array(vectorizer.get_feature_names())\n",
    "    tfidf_sorting = np.argsort(response.toarray()).flatten()[::-1]\n",
    "    n = 50\n",
    "    top_n = feature_array[tfidf_sorting][:n]\n",
    "    print(i, top_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
