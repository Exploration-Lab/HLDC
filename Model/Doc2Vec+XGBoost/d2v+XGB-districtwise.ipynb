{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9c28a-c08e-4aea-b243-a6e964b4222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import codecs\n",
    "import argparse\n",
    "import logging\n",
    "import shutil\n",
    "import json\n",
    "from random import shuffle, randint\n",
    "from datetime import datetime\n",
    "from collections import namedtuple, OrderedDict\n",
    "import multiprocessing\n",
    "from smart_open import open\n",
    "from tqdm.auto import tqdm\n",
    "import gensim\n",
    "import gensim.models.doc2vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "import time\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba50e4-a812-4808-b18a-a5cb67c7216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec(X_train,y_train,X_test,y_test,xg_g=0,trial=None,num_epochs=0,alpha=0.015):\n",
    "  stopwords_path='/home2/username/legal-tech/hindi_stop.txt'\n",
    "  vocab_min_count=5\n",
    "  if trial!=None:\n",
    "      num_epochs=trial.suggest_int(\"num_epochs\", 50, 100)\n",
    "      alpha = trial.suggest_float(\"alpha\", 0.005, 0.05)\n",
    "  algorithm=\"pv_dmc\"\n",
    "  vector_size=200\n",
    "  min_alpha=0.001\n",
    "  window=5\n",
    "  negative = 5\n",
    "  hs = 0\n",
    "  def read_lines(path):\n",
    "    return [line.strip() for line in codecs.open(path, \"r\", \"utf-8\")]\n",
    "  def load_stopwords(stopwords_path):\n",
    "    stopwords = read_lines(stopwords_path)\n",
    "    return dict(map(lambda w: (w.lower(), ''), stopwords))\n",
    "  assert gensim.models.doc2vec.FAST_VERSION > - \\\n",
    "        1, \"This will be painfully slow otherwise\"\n",
    "  stopwords = load_stopwords(stopwords_path)\n",
    "  cores = multiprocessing.cpu_count()\n",
    "  docs=[]\n",
    "  for i , doc in enumerate(X_train):\n",
    "    words = doc.replace(\"\\n\",\" \").replace(\"ред\", \" \")\n",
    "    words = re.sub(r'[^\\w\\s]', \" \", words).split()\n",
    "    words = [w for w in words if w not in stopwords and len(w) > 1]\n",
    "    tags=[i]\n",
    "    docs.append(TaggedDocument(words=words, tags=tags))\n",
    "  if algorithm == 'pv_dmc':\n",
    "        model = Doc2Vec(dm=1, dm_concat=1, vector_size=vector_size, window=window, negative=negative, hs=hs,\n",
    "                        min_count=vocab_min_count, workers=cores)\n",
    "  elif algorithm == 'pv_dma':\n",
    "      model = Doc2Vec(dm=1, dm_mean=1, vector_size=vector_size, window=window, negative=negative, hs=hs,\n",
    "                      min_count=vocab_min_count, workers=cores)\n",
    "  elif algorithm == 'pv_dbow':\n",
    "      model = Doc2Vec(dm=0, vector_size=vector_size, window=window, negative=negative, hs=hs,\n",
    "                      min_count=vocab_min_count, workers=cores)\n",
    "  vocab_size = len(model.wv.index_to_key)\n",
    "  model.build_vocab(docs)\n",
    "  shuffle(docs)\n",
    "  print(\"Training\")\n",
    "  model.train(docs, total_examples=len(docs),\n",
    "              epochs=num_epochs, start_alpha=alpha, end_alpha=min_alpha,report_delay=60)\n",
    "  Xtr=[]\n",
    "  for i , doc in enumerate(X_train):\n",
    "    Xtr.append(model.dv.get_vector(i))\n",
    "  Xte=[]\n",
    "  for i , doc in enumerate(X_test):\n",
    "    words = doc.replace(\"\\n\",\" \").replace(\"ред\", \" \")\n",
    "    words = re.sub(r'[^\\w\\s]', \" \", words).split()\n",
    "    words = [w for w in words if w not in stopwords and len(w) > 1]\n",
    "    Xte.append(model.infer_vector(words))\n",
    "  from sklearn.svm import SVC\n",
    "  print(\"Classifying\")\n",
    "  if trial!=None:\n",
    "      xg_g = trial.suggest_int(\"xg_g\", 100, 500)\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  clf = GradientBoostingClassifier(criterion='friedman_mse',n_estimators=xg_g,random_state=0).fit(Xtr, y_train)\n",
    "  clf.fit(Xtr, y_train)\n",
    "  from sklearn.metrics import classification_report\n",
    "  y_pred = clf.predict(Xte)\n",
    "  if trial==None:\n",
    "    plot_confusion_matrix(clf, Xte, y_test)\n",
    "    plt.savefig(\"/home2/username/legal-tech/doc2vec-dw-xg.png\",dpi=300)\n",
    "    with open(\"./doc2vec-dw-xg.pkl\",\"wb\") as f:\n",
    "        pickle.dump(clf,f)\n",
    "    model.save(\"./doc2vec-dw-xg.model\")\n",
    "  return classification_report(y_test, y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d7ea59-57d8-4d1c-9c10-46ca3d854842",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/scratch/username/train_test_data_for_modelling/test_split_17_districts.json\") as f:\n",
    "    data = json.load(f)\n",
    "    df = pd.DataFrame(data)\n",
    "    #df = df.head(100)\n",
    "    df2 = df.sample(frac = 0.1, random_state=42).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb565e61-83c7-4638-8ded-b6180584d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df[\"segments\"].apply(lambda x:\" \".join(x[\"facts-and-arguments\"])).tolist()\n",
    "y_test = df[\"decision\"].apply(lambda x: 1 if x == \"granted\" else 0).tolist()\n",
    "hX_test = df2[\"segments\"].apply(lambda x:\" \".join(x[\"facts-and-arguments\"])).tolist()\n",
    "hy_test = df2[\"decision\"].apply(lambda x: 1 if x == \"granted\" else 0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f9f0bf-199d-49ca-b24b-69a7fd33e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/scratch/username/train_test_data_for_modelling/train_split_44_districts.json\") as f:\n",
    "    data = json.load(f)\n",
    "    df = pd.DataFrame(data)\n",
    "    #df = df.head(100)\n",
    "    df2 = df.sample(frac = 0.1, random_state=42).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac72f97-606b-4abf-8630-f0e4095bf374",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[\"segments\"].apply(lambda x:\" \".join(x[\"facts-and-arguments\"])).tolist()\n",
    "y_train = df[\"decision\"].apply(lambda x: 1 if x == \"granted\" else 0).tolist()\n",
    "hX_train = df2[\"segments\"].apply(lambda x:\" \".join(x[\"facts-and-arguments\"])).tolist()\n",
    "hy_train = df2[\"decision\"].apply(lambda x: 1 if x == \"granted\" else 0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf806e8-03d3-4027-8ab0-10b502e8659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    rep = doc2vec(hX_train,hy_train,hX_test,hy_test,xg_g=None,trial=trial,num_epochs=0,alpha=0.015)\n",
    "    accuracy = rep[\"accuracy\"]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ad472-8e33-4614-b515-46f6c8cbdaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6844eb-b594-4c5b-980c-464aa84a7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    if key==\"xg_g\":\n",
    "        xg_g=value\n",
    "    if key==\"num_epochs\":\n",
    "        num_epochs=value\n",
    "    if key==\"alpha\":\n",
    "        alpha=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ebf91-6408-4bd0-9a5e-06e165e1031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = doc2vec(X_train,y_train,X_test,y_test,xg_g=xg_g,trial=None,num_epochs=num_epochs,alpha=alpha)\n",
    "print(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f216e-de11-4ebb-aba1-3c11af1503fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home2/username/legal-tech/doc2vec-dw-xg.json\",\"w\") as f:\n",
    "    json.dump(rep,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc53d5-9689-4aaf-a504-b59a898597df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
