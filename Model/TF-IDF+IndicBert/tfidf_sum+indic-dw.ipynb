{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489057c-0e87-47e8-97f7-0a630d6eadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1778e89-05f3-4fbd-a4ff-5b5f19e36ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185d897-cde9-4e05-99ba-5a19efd91597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\"ai4bharat/indic-bert\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5f6a6-251f-486c-9991-12a04862a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b943277e-f9a4-424c-aaa3-74332f61b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/scratch/username/tfidf_summaries/train_split_44_districts.csv\")\n",
    "test_df = pd.read_csv(\"/scratch/username/tfidf_summaries/validation_split_10_districts.csv\")\n",
    "#train_df = train_df.head(500)\n",
    "#test_df = test_df.head(500)\n",
    "hp_train_df = train_df.sample(frac = 0.1, random_state=42).reset_index()\n",
    "hp_test_df = test_df.sample(frac = 0.1, random_state=42).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1187d44-7724-4bbc-b33b-dcc002de74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.df[\"text\"] = self.df[\"ranked-sentences\"].progress_apply(lambda x:\" \".join(eval(x)[:10]))\n",
    "        self.df[\"label\"] = self.df[\"decision\"].progress_apply(lambda x:1 if x==\"granted\" else 0)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        model_input = self.df['text'][idx]            \n",
    "        encoded_sent = self.tokenizer.encode_plus(\n",
    "            text=model_input, \n",
    "            add_special_tokens=True,       \n",
    "            max_length=512,                  \n",
    "            padding='max_length',          \n",
    "            return_attention_mask=True, \n",
    "            truncation=True\n",
    "            )\n",
    "        \n",
    "        input_ids = encoded_sent.get('input_ids')\n",
    "        attention_mask = encoded_sent.get('attention_mask')\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        attention_mask = torch.tensor(attention_mask)        \n",
    "\n",
    "        label = torch.tensor(self.df['label'][idx])\n",
    "        \n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57773094-f2dd-4aae-9eb9-ffb3837f37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LegalDataset(train_df, tokenizer)\n",
    "test_dataset = LegalDataset(test_df, tokenizer)\n",
    "hp_train_dataset = LegalDataset(hp_train_df, tokenizer)\n",
    "hp_test_dataset = LegalDataset(hp_test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167dbcbc-389f-45d4-80e0-b765e1dfac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric1 = load_metric(\"accuracy\")\n",
    "metric2 = load_metric(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42716a-745e-4727-8e01-ea363abedea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = metric1.compute(predictions=predictions, references=labels)\n",
    "    f1 = metric2.compute(predictions=predictions, references=labels, average=\"micro\")\n",
    "    return {'accuracy': accuracy[\"accuracy\"], 'f1-score': f1[\"f1\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51569c0c-6377-403e-b2c9-ba33e8290bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"weight_decay\":trial.suggest_float(\"weight_decay\", 0.005, 0.05),\n",
    "        \"adam_beta1\":trial.suggest_float(\"adam_beta1\", 0.75, 0.95),\n",
    "        \"adam_beta2\":trial.suggest_float(\"adam_beta2\", 0.99, 0.9999),\n",
    "        \"adam_epsilon\":trial.suggest_float(\"adam_epsilon\", 1e-9, 1e-7, log=True)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf81c2-18fe-4bde-b2c1-bb7b7a571c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='/scratch/username/htf1_results',          # output directory\n",
    "    num_train_epochs=5,            # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
    "    warmup_steps=500,               # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,              # strength of weight decay\n",
    "    logging_dir='/scratch/username/htf1_logs',           # directory for storing logs\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=250,\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit = 1,\n",
    "    learning_rate = 0.00001,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model =\"eval_f1-score\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73102706-55c1-4c83-a6e1-34870dbfc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,                        # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=hp_train_dataset,         # training dataset\n",
    "    eval_dataset=hp_test_dataset,           # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861aa998-6334-498a-b2e8-f12a58039340",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(n_trials=10,direction=\"maximize\",hp_space=my_hp_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be5278-a464-487d-b15d-04bbd6b0c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best HyperParameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33eaac8-878d-49d6-b75f-be7666736f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2bacb-b8b3-4ade-ad31-3df04cfff6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer\n",
    "del training_args\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1868ea-2697-49e5-95ec-87038d6e4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016961c4-a64a-41a2-85b5-bc97d968ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='/scratch/username/tf1_results',          # output directory\n",
    "    num_train_epochs=15,            # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
    "    warmup_steps=500,               # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,              # strength of weight decay\n",
    "    logging_dir='/scratch/username/tf1_logs',           # directory for storing logs\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=250,\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit = 1,\n",
    "    learning_rate = 0.00001,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model =\"eval_f1-score\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13ccc5-14c5-4d51-ac66-1428260e6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,                        # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,           # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c54ab-3406-4d09-9742-ff1a95e45423",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(trainer.args, n, v)\n",
    "print(trainer.args)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b3b80-7013-4e1d-ae8f-54b10a68918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"/home2/username/legal-tech/tfidf_sum+indic-dw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc1ada-9468-474c-b9d3-190ea806fabf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
